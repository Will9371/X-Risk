%YAML 1.1
%TAG !u! tag:unity3d.com,2011:
--- !u!114 &11400000
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 0}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 4df6a31ec318a254eae9af3311b7aaaf, type: 3}
  m_Name: 1 - Long Term X-Risk
  m_EditorClassIdentifier: 
  narrative: X-risk (existential risk) refers to a catastrphoic event that causes
    human extinction.  X-risk is not limited to AI, but also includes other massively
    destructive events, such as large-scale nuclear war, runaway global warming,
    a giant meteor, a sufficiently deadly pandemic, and so on.  I am focusing on
    AI as a source of x-risk because it seems to be on the shortest timeline and
    because, if aligned successfully, could be used to mitigate other sources of
    x-risk.
  showConditionalResponses: 0
  responses:
  - node: {fileID: 11400000, guid: e9edfa69e10f1b24e9f082a6ecb66ed0, type: 2}
    response: How is AI an x-risk?
    showConditionalResponses: 0
    logicalRequirement:
      requirements: []
      invert: 0
    relationalRequirement:
      requirements: []
      invert: 0
    fallbackNode: {fileID: 0}
    fallbackResponse: 
  - node: {fileID: 11400000, guid: 4284b117cf6fce64b9d9e8d0c669ea25, type: 2}
    response: Maybe the extinction of humanity isn't so bad.  Maybe we should humbly
      step aside and let the next phase of evolution replace us...
    showConditionalResponses: 0
    logicalRequirement:
      requirements: []
      invert: 0
    relationalRequirement:
      requirements: []
      invert: 0
    fallbackNode: {fileID: 0}
    fallbackResponse: 
  - node: {fileID: 11400000, guid: d3f1141619dedf142a55538a8c0180c8, type: 2}
    response: You're just some luddite peddling science fiction!  If you knew what
      you were talking about, you'd know there's nothing to be afraid of...
    showConditionalResponses: 0
    logicalRequirement:
      requirements: []
      invert: 0
    relationalRequirement:
      requirements: []
      invert: 0
    fallbackNode: {fileID: 0}
    fallbackResponse: 
  - node: {fileID: 11400000, guid: 3e1b9e18330bdde4c8d2a0a24705c71a, type: 2}
    response: Return to Chapter Select
    showConditionalResponses: 0
    logicalRequirement:
      requirements: []
      invert: 0
    relationalRequirement:
      requirements: []
      invert: 0
    fallbackNode: {fileID: 0}
    fallbackResponse: 
  castChanges: []
  occasions: []
  events: []
