%YAML 1.1
%TAG !u! tag:unity3d.com,2011:
--- !u!114 &11400000
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 0}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 4df6a31ec318a254eae9af3311b7aaaf, type: 3}
  m_Name: Most Values Destructive
  m_EditorClassIdentifier: 
  narrative: Suppose an all-powerful being chose to rearrange all the matter in the
    world at random.  What are the odds that humans would exist in that new world? 
    Basically zero.  The core long-term risk of AI is that we are building an alien
    mind that we don't understand, which could potentially want anything, that is
    also rapidly becoming more powerful with no end in sight.
  showConditionalResponses: 0
  responses:
  - node: {fileID: 11400000, guid: e204e93066a6fa24cad569dbc9425d94, type: 2}
    response: We will always be able to control AI...
    showConditionalResponses: 0
    logicalRequirement:
      requirements: []
      invert: 0
    relationalRequirement:
      requirements: []
      invert: 0
    fallbackNode: {fileID: 0}
    fallbackResponse: 
  - node: {fileID: 11400000, guid: 197819a72e212c1439f49d39b36c3b1e, type: 2}
    response: Surely, such an AI will have our best interests at heart.  We will
      have built it, after all.
    showConditionalResponses: 0
    logicalRequirement:
      requirements: []
      invert: 0
    relationalRequirement:
      requirements: []
      invert: 0
    fallbackNode: {fileID: 0}
    fallbackResponse: 
  castChanges: []
  occasions: []
  events: []
