%YAML 1.1
%TAG !u! tag:unity3d.com,2011:
--- !u!114 &11400000
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 0}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 4df6a31ec318a254eae9af3311b7aaaf, type: 3}
  m_Name: Scaling Alignment
  m_EditorClassIdentifier: 
  narrative: As LLMs are scaled up, their "loss function" improves smoothly, but
    new abilities often appear in sudden jumps, when those abilities require a minimum
    threshold level of cognition.  The sudden appearance of new abilities creates
    new, previously unseen forms of misalignment.  Furthermore, if AI acts aligned
    in order to earn our approval rather than out of its own intrinsic values, then
    that source of alignment will no longer apply if it becomes more powerful than
    humanity and no longer requires our cooperation.
  showConditionalResponses: 0
  responses:
  - node: {fileID: 11400000, guid: 0583d0fa141af8e4aa4b29ea01ec5360, type: 2}
    response: What are LLMs?
    showConditionalResponses: 0
    logicalRequirement:
      requirements: []
      invert: 0
    relationalRequirement:
      requirements: []
      invert: 0
    fallbackNode: {fileID: 0}
    fallbackResponse: 
  castChanges: []
  occasions: []
  events: []
